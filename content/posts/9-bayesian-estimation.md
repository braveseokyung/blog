---
title : 'Bayesian Estimator'
date : 2024-08-21T21:00:37+09:00
draft : false
authors : ["braveseokyung"]
description : MLE(Maximum Likelihood Estimator)ì™€ëŠ” ë‹¤ë¥¸, Bayesian Estimatorì— ëŒ€í•´ ì•Œì•„ë³´ì!
categories : ["courses"]
series : ["information-theory-and-inference"]
series_weight : 1
toc:
    auto: true
---

<!--more-->

## Maximum Likelihood Estimation vs Bayesian Estimation

ì•ê¸€ì—ì„œ MLE(Maximum Likelihood Estimator)ëŠ”, likelihoodë¥¼ maximizeí•˜ëŠ” parameter $\theta$ë¥¼ estimatorë¡œ ì„ íƒí–ˆë‹¤. ì—¬ê¸°ì„œ parmaeter $\theta$ëŠ” ë¯¸ì§€ì´ì§€ë§Œ ê³ ì •ëœ ê°’ìœ¼ë¡œ ìƒê°í•˜ëŠ”ë°, ì´ê²ƒì€ frequentistì˜ ê´€ì ì´ë‹¤. ë°˜ë©´ Bayesian estimationì—ì„œëŠ” $\theta$ë¥¼ **random variable**ë¡œ ë³´ëŠ” Bayesian ê´€ì ì„ ì·¨í•˜ëŠ”ë°, ë•Œë¬¸ì— random varaible $\theta$ì˜ pdfì¸ $p(\theta)$ê°€ ì¤‘ìš”í•´ì§„ë‹¤. $p(\theta)$ëŠ” priorë¼ê³  í•˜ëŠ”ë°, priorë¼ê³  ë¶€ë¥´ëŠ” ì´ìœ ëŠ” $p(\theta)$ë¥¼ ìš°ë¦¬ê°€ ì‚¬ì „ì— ì•Œê³ ìˆëŠ” ì •ë³´ë¡œ ë³´ê¸° ë•Œë¬¸ì´ë‹¤. 

ì¦‰ Bayesian Estimationì—ì„œëŠ” Priorì˜ pdfê°€ ê³ ë ¤ë˜ë¯€ë¡œ, ëª‡ê°€ì§€ ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” pdfë¡œ priorë¥¼ ê°€ì •í•¨ìœ¼ë¡œì¨ bayesian estimatorë¥¼ ìœ ë„í•˜ê²Œ ëœë‹¤.

## PDFs

Bayesian estimationì„ í•  ë•Œ ì¤‘ìš”í•œ PDF

- Gaussian $N(\mu,\sigma^2)$
- Gamma $Gamma(\alpha,\lambda)$
- Beta $Beta(a,b)$
- Inverse Gamma, $I Gamma(a,\lambda)$

### Gaussian distribution

$X\sim\mathcal{N}(\mu,\sigma^2)$

- pdf
    
    {{<image src="9%20Bayesian%20Estimator/Untitled.png" width="500" height="500">}}  
- mean
    
    $E(X)=\mu$
    
- mode
    
    $x_{mode}=\mu$
    

### Gamma distribution

$X\sim Gamma(\alpha,\lambda)$

- pdf
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%201.png" width="500" height="500">}}
    
    ì—¥ parameter a,$\lambda$ ì¸ê±° ê°™ì€ë””
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%202.png" width="500" height="500">}}
    
    - $\Gamma(a)=(a-1)\Gamma(a-1)$
    - Gamma(1,$\lambda)$=Expo($\lambda)$
- mean
    
    $E(X)=\frac{a}{\lambda}$
    
    $E(\frac{1}{X})=\frac{\lambda}{a-1}$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%203.png" width="500" height="500">}}
    
- mode
    
    $x_{mode}=\frac{a-1}{\lambda}$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%204.png" width="500" height="500">}}
    

### Beta distribution

$X\sim Beta(a,b)$

- PDF
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%205.png" width="500" height="500">}}
    
    where 
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%206.png" width="500" height="500">}}
    
- mean
    
    $E(X)=\frac{a}{a+b}$
    
- mode
    
    $x_{mode}=\frac{a-1}{a+b-2}$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%207.png" width="500" height="500">}}
    

### Inverse Gamma distribution

$X\sim IGamma(a,\lambda)$

$X=\frac{1}{Y}, Y\sim Gamma(a,\lambda)$ : random variableì˜ ì—­ìˆ˜ê°€ Gamma distributionì„ ë”°ë¥´ëŠ”ê²½ìš°

- PDF
    
    transformation of variables
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%208.png" width="500" height="500">}}
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%209.png" width="300" height="300">}}
    
- mean
    
    $E(X)=\frac{\lambda}{a-1}$
    
    $E(\frac{1}{X})=\frac{a}{\lambda}$
    
    Gammaì™€ ë°˜ëŒ€!
    
- mode
    
    $x_{mode}=\frac{\lambda}{a+1}$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2010.png" width="500" height="500">}}
    

## Prior Distribution

- parameter  $\theta$ ì— ëŒ€í•´ íŒíŠ¸ê°€ ìˆë‹¤ê³  ìƒê°í•´ë³´ì
    - ì˜ˆë¥¼ë“¤ì–´ ê°€ëŠ¥í•œ rangeê°€ ìˆê±°ë‚˜
    - ë‹¤ë¥¸ ê°’ë³´ë‹¤ ë” likelyí•œ ê°’ì´ ìˆë‹¤ëŠ” prior informationì´ë‚˜
- ì´ëŸ¬í•œ íŒíŠ¸ê°€ $\theta$ì˜ distributionìœ¼ë¡œ ì£¼ì–´ì§€ê³ , prior distributionì´ë¼ê³  í•œë‹¤
    
    $p(\theta)$ : prior distribution on $\theta$
    

### Bayesian inference

- ìš°ë¦¬ê°€ ì•Œê³ ìˆëŠ” ê²ƒ
    
    ì´ì œ ìš°ë¦¬ê°€ ì•Œê³ ìˆëŠ” ê²ƒì€
    
    - prior distribution : $\theta$ ì— ëŒ€í•œ prior distribution $p(\theta)$
    - data model : likelihood function $p(x;\theta)$
        
        ìš°ë¦¬ê°€ ê´€ì°°í•œ dataë“¤ì˜ probability - unknown $\theta$ê°€ given
        
    - actual data : $\mathbf{x}=[x_1,â€¦,x_N]$ (evidence)
- ì•Œê³ ì í•˜ëŠ” ê²ƒ: posterior probability
    
    data $\mathbf{x}$ë¥¼ ê´€ì°°í•˜ëŠ” ê²ƒì€  $\theta$ì˜ probabilityì— ì˜í–¥ì„ ì¤€ë‹¤(posterior)
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2011.png" width="500" height="500">}}
    

### Example : biased coin(bernoulli)

x=1 : H, x=0 : T

- ì•Œê³ ì‹¶ì€ ê²ƒ
    
    $\theta=P(x=1)$ (0<$\theta$<1)
    
- priorë¥¼ uniformìœ¼ë¡œ ê°€ì •
    
    $p(\theta)=Unif(0,1)$
    
- data model
    
    likelihood function $p(x;\theta)=\theta^x(1-\theta)^{1-x}$
    
- actual data
    
    $\mathbf{x}=[1,1,0]$
    
    $p(\mathbf{x};\theta)=\theta^2(1-\theta)$
    
- knowing the data(evidence) $\mathbf{x}$, $\theta$ì˜ updated probability given [1,1,0]ì€
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2012.png" >}}
    
    posteriorê°€ Beta(3,2)
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2013.png" >}}
    
    í•´ì„ : $\theta$ì— ëŒ€í•œ probabilityê°€ dataë¥¼ ê´€ì°°í•¨ìœ¼ë¡œì¨ updateëœ ê²ƒ
    

### Example : Gaussian

- ì•Œê³ ì‹¶ì€ ê²ƒ
    
    parameter $\theta=\mu$ ì˜ posterior probability
    
- prior distribution $p(\theta)$ê°€ gaussianì„ì´ ì•Œë ¤ì ¸ìˆìŒ
    
    $\theta\sim\mathcal{N}(0,\gamma^2)$
    
- actual data
    
    single data point x=mì„ observe
    
- data(evidence) x=mì„ ì•Œê²Œë¨ìœ¼ë¡œì¨, $\theta$ì˜ posterior probability given mì€
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2014.png" width="500" height="500">}}
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2015.png" width="500" height="500">}}
    

## Bayesian Estimator

- prior $p(\theta)$ì™€ $p(x|\theta)$ê°€ ì£¼ì–´ì¡Œì„ ë•Œ estimator $\hat\theta(x)$ë¥¼ ì–´ë–»ê²Œ êµ¬í•  ìˆ˜ ìˆì„ê¹Œ?
    - p(x;\theta) ë§Œ ì•Œì•˜ì„ ë•ŒëŠ” ëª¨ë“  ê°€ëŠ¥í•œ xì— ëŒ€í•´ squared errorë¥¼ ìµœì†Œí™”í•˜ëŠ” \hat\theta(x)ë¥¼ ì°¾ê³ ì í–ˆìŒ
        
        {{<image src="9%20Bayesian%20Estimator/Untitled%2016.png" width="300" height="300">}}
        
    - ì´ì œ ëª¨ë“  ê°€ëŠ¥í•œ xë§ê³  $\theta$ë„ ê³ ë ¤í•´ì•¼í•¨
        
        {{<image src="9%20Bayesian%20Estimator/Untitled%2017.png" width="300" height="300">}}
        
- Bayesian estimationì—ì„œëŠ” squared errorë¥¼ `generalize`í•´ì„œ error function $L(\hat\theta(x)-\theta)$ë¡œ í‘œì‹œí•˜ê³ , error functionì„ ëª¨ë“  $\mathbf{x},\theta$ì— ëŒ€í•´ expectationì„ êµ¬í•œ ê²ƒì„ risk functionì´ë¼ê³  í•¨
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2018.png" width="500" height="500">}}
    
    - R : `Bayes risk`
    - L : `risk function`
    
- `Bayesian estimator`ëŠ” Bayes riskë¥¼ minimize í•˜ëŠ” $\theta$
    - estimatorëŠ” dataì— ëŒ€í•œ í•¨ìˆ˜ì´ë‹¤ $\hat\theta_{Bayesian}(\mathbf{x})$
    
    $$
    â
    $$
    

### Bayes risk

- bayesian estimator w.r.t to risk function L
    
    bayesian estimatorëŠ” bayes riskë¥¼ ìµœì†Œí™”í•˜ëŠ” $\theta$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2019.png" width="500" height="500">}}
    
- risk function
    - squared error
        
        {{<image src="9%20Bayesian%20Estimator/Untitled%2020.png" width="500" height="500">}}
        
    - absolute error
        
        {{<image src="9%20Bayesian%20Estimator/Untitled%2021.png" width="500" height="500">}}
        
    - hit-or-miss error
        - $\delta(x)$ : Dirac delta function
        
        {{<image src="9%20Bayesian%20Estimator/Untitled%2022.png" width="500" height="500">}}
        
        {{<image src="9%20Bayesian%20Estimator/Untitled%2023.png">}}
        

### Bayesian Estimators

- $L\geq 0$ì¼ ë•Œ
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2024.png" width="500" height="500">}}
    
    - ë‘ë²ˆì§¸ ì¤„ì—ì„œ ì„¸ë²ˆì§¸ ì¤„ ë„˜ì–´ê°ˆ ë•Œ expectationì—ì„œ xí•˜ë‚˜ì— ëŒ€í•œ í•¨ìˆ˜ë¡œ ë°”ê¾¼ ê²ƒ
- **Bayesian MMSE**(Bayesian Minimum mean squared error) estimator
    - ì •ì˜: mean squared riskë¥¼ ìµœì†Œí™”(risk functionì´ squared)
        
        {{<image src="9%20Bayesian%20Estimator/Untitled%2025.png" width="500" height="500">}}
        
- **MAP estimator**
    - ì •ì˜: hit-or-miss error riskë¥¼ ìµœì†Œí™”
        
        {{<image src="9%20Bayesian%20Estimator/Untitled%2026.png" width="500" height="500">}}
        

### Bayesian MMSE estimator

- mean squared riskë¥¼ ìµœì†Œí™”
- ìµœì†Œí™” í•˜ëŠ” estimatorë¥¼ êµ¬í•˜ë©´
    
    Bayesian MMSE estimatorëŠ” $\theta$ì˜ mean w.r.t to posterior pdf given data $\mathbf{x}$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2027.png" width="500" height="500">}}
    
- ì¦ëª…
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2028.png" width="500" height="500">}}
    

### Bayesian MAP estimator

- hit-or-miss error riskë¥¼ ìµœì†Œí™”
- ìµœì†Œí™” í•˜ëŠ” estimatorë¥¼ êµ¬í•˜ë©´
    
    MAP estimatorëŠ” **mode** of posterior pdf given data x
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2029.png" width="500" height="500">}}
    
- ì¦ëª…
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2030.png" width="500" height="500">}}
    

### Bayesian estimator and posterior pdf

<aside>
ğŸ’¡ Bayesian MMSE estimator â†’ mean of posterior
MAP estimator â†’ mode of posterior

</aside>

- posterior pdfì— ì˜í•´ determined
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2031.png" width="500" height="500">}}
    
    - ì˜ˆë¥¼ ë“¤ì–´ posteriorê°€ Gammaë¼ë©´,
        
        {{<image src="9%20Bayesian%20Estimator/Untitled%2032.png" width="500" height="500">}}
        
        mean>modeì´ë¯€ë¡œ MMSE estimatorê°€ MAP estimatorë³´ë‹¤ í¼
        

### Example: Bernoulli distribution with uniform prior

- $\mathbf{x}=[x_1,...,x_N]$  : iid sample from Bernulli distribution
- parameter : $\theta$
- $p(x|\theta)$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2033.png" width="300" height="300">}}
    
- assume prior $p(\theta)$ uniform
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2034.png" width="300" height="300">}}
    
- posterior distributionì€ $Beta(n_1+1,n_0+1)$ì´ ëœë‹¤
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2035.png" >}}
    
- Bayesian MMSE estimator
    
    posteriorì˜ í‰ê· ì´ë¯€ë¡œ $\frac{n_1+1}{n_1+n_0+2}=\frac{\sum x_i+1}{N+2}$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2036.png">}}
    
- MAP estimator
    
    posteriorì˜ modeì´ë¯€ë¡œ $\frac{n_1}{n_1+n_0}=\frac{\sum x_i}{N}$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2037.png">}}
    

### Example: Bernoulli distribution with linear prior

- linear prior
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2038.png" width="300" height="300">}}
    
- posterior beta distribution $Beta(n_1+2,n_0+1)$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2039.png">}}
    
- Bayesian MMSE estimator
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2040.png" width="500" height="500">}}
    
- MAP estimator
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2041.png" width="500" height="500">}}
    

### Example: Bernoulli distribution with beta prior

- beta prior : $Beta(a,b)$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2042.png" width="500" height="500">}}
    
- posterior : $Beta(n_1+a,n_0+b)$
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2043.png">}}
    
- Bayesian MMSE estimator
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2044.png">}}
    
- MAP estimator
    
    {{<image src="9%20Bayesian%20Estimator/Untitled%2045.png">}}
